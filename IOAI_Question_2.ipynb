{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "prguuvsDQEU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RNb9baK4M24w"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "read_access_token = userdata.get('read_token')\n",
        "write_access_token = userdata.get('write_token')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import torch, transformers\n",
        "\n",
        "if '2.3.0' not in torch.__version__:\n",
        "  !pip install torch==2.3.0\n",
        "if transformers.__version__!='4.41.2':\n",
        "  !pip install transformers==4.41.2\n",
        "\n",
        "if importlib.util.find_spec('datasets') is None:\n",
        "  !pip install datasets==2.18.0\n",
        "  !pip install evaluate==0.4.2\n",
        "  !pip install accelerate -U"
      ],
      "metadata": {
        "id": "mKiT0nzuPh_N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "7oczTAS0QGtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "classification_dataset = load_dataset('InternationalOlympiadAI/NLP_problem', token=read_access_token)\n",
        "raw_text = load_dataset('InternationalOlympiadAI/NLP_problem_raw', token=read_access_token)"
      ],
      "metadata": {
        "id": "bksa0G7CPk3d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing and Model Training Configuration"
      ],
      "metadata": {
        "id": "UI57chiHRqwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre-trained tokenizer and use it to process the data\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_data = classification_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h61TEWLkRylW",
        "outputId": "7183166d-c6be-4b0e-e73f-b37bdbd6f7c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the evaluation metric\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)  #Converts Predictions into Class Labels\n",
        "    #np.argmax returns the col with highest probability which can be used to associate sample with label\n",
        "    return f1.compute(predictions=predictions, references=labels, average='macro')    #Returns F1 Score"
      ],
      "metadata": {
        "id": "To0UxGayR7ct"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model and training configuration\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-multilingual-uncased\", num_labels=5    #5 possible classes\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"basiline_bobai\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=20,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=5,\n",
        "    metric_for_best_model='f1',\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"checkpoint\",\n",
        "    hub_token=write_access_token,\n",
        "    hub_private_repo=True,\n",
        "    hub_model_id='baseline_bobai'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"dev\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,   #Data collator pads data in order to make all inputs same size\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0VHkhMHR-7l",
        "outputId": "09b1b503-f1ef-43f6-859f-3712b2095d62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "OJT1E3uNSBNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "fBoBRs39SCbt",
        "outputId": "a42c8c78-18e6-4b27-899d-118a6b04c721"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 09:25, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.576072</td>\n",
              "      <td>0.162946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.534276</td>\n",
              "      <td>0.271737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.501180</td>\n",
              "      <td>0.259241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.456529</td>\n",
              "      <td>0.278207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.441857</td>\n",
              "      <td>0.291475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.434299</td>\n",
              "      <td>0.261979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.423065</td>\n",
              "      <td>0.288901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.432266</td>\n",
              "      <td>0.305457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.414659</td>\n",
              "      <td>0.334584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.402321</td>\n",
              "      <td>0.325904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.385726</td>\n",
              "      <td>0.298937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.400937</td>\n",
              "      <td>0.334924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.394233</td>\n",
              "      <td>0.306694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.379291</td>\n",
              "      <td>0.336802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.381346</td>\n",
              "      <td>0.343404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.360644</td>\n",
              "      <td>0.346143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.365556</td>\n",
              "      <td>0.354749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.370888</td>\n",
              "      <td>0.361370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.365684</td>\n",
              "      <td>0.360490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.364398</td>\n",
              "      <td>0.355239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=480, training_loss=1.3949156443277995, metrics={'train_runtime': 566.6873, 'train_samples_per_second': 53.786, 'train_steps_per_second': 0.847, 'total_flos': 372809629324656.0, 'train_loss': 1.3949156443277995, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the trained model on a dev/test split\n",
        "data_split = \"dev\"\n",
        "eval_out = trainer.predict(tokenized_data[data_split])\n",
        "predictions = eval_out.predictions.argmax(1)\n",
        "labels = eval_out.label_ids\n",
        "dev_f1 = f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4Gjx-xu_SGQF",
        "outputId": "1c9d139c-ba1e-4638-cd83-81f2ad3e59e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13cyEUyjU7b9",
        "outputId": "199025fe-9d3c-4236-ea0f-f447d0b69b6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'f1': 0.3613697747396801}\n"
          ]
        }
      ]
    }
  ]
}